Задача
Имеется ETL сервис, который агрегирует данные из различных источников.
Полученные данные хранятся в pg и визуализируются, используя BI систему.
Собираемая информация гибко настраивается с помощью фильтров,
например: issue tag: X and Updated > Y.
Очевидно, что один и тот же фильтр в разные моменты времени может вернуть дубликаты, необходимо уметь гибко их обрабатывать.

Решения
Организация фильтров таких образом, чтобы избежать дубликатов
Фильтрация на уровне кода
Фильтрация на уровне селекторов BI
Нормализация на уровне базы данных

Ограничения
Решение должно быть стабильным и масштабируемым. Устойчивым к неожиданному изменению фильтров людьми, что не погружены в детали реализации: менеджеры, тестировщики.

Решение
Вероятно очевидно, что наиболее приоритетным и правильным решением является нормализация на уровне БД, то есть создание первичного ключа на базе уникальной комбинации полей рассматриваемых данных. В таком случае из коробки мы получаем также возможность гибко задавать поведение запроса при конфликте вставки данных (фактически наличии дубликата), используя ON CONFLICT в pg. Подобное решение так же устойчиво к изменениям фильтра, если, например, объем дубликатов резко увеличился. Однако в реальности, в виду неопытности или чего-то еще, возможны и другие варианты решения, кратко рассмотрим:

Организация фильтров таких образом, чтобы избежать дубликатов
Даже если и реализовать каким-то образом, не является надежным, по причине изменчивости объема данных и ограничению, что фильтры могут изменяться сторонними людьми.

Фильтрация на уровне кода
Ненужное увеличение объема кода и его усложнение, сложно поддерживать + вероятно также потребуются добавление служебных полей в таблицу

Фильтрация на уровне селекторов BI
Большие издержки для конечного пользователя, по сути фильтрация на фронтенде, увеличение времени рендеринга и соответственно ожидания пользователя + потенциально бОльшее погружение в инструменты BI системы